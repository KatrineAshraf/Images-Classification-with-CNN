{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRmJ3Qzr_HJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452f9c24-6d36-49de-e695-920e9a4c684e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "exfrom google.colab import drive\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1f6jT_MSh9D5srF1-gLD-AKuCnDs-EzwF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0c5t-fGXZay",
        "outputId": "64c9eacb-d8ab-4f79-e2dc-218f88d00daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1f6jT_MSh9D5srF1-gLD-AKuCnDs-EzwF \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip DL_Assignment_1_Data.zip"
      ],
      "metadata": {
        "id": "kUc8exRgXh5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc50dd3-4531-410c-cb65-78b45eca5536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open DL_Assignment_1_Data.zip, DL_Assignment_1_Data.zip.zip or DL_Assignment_1_Data.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBE-UP1eVF6U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Conv2D,Flatten,MaxPooling2D,Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, MaxPool2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import ReLU, concatenate\n",
        "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puUDnzwSV4sz"
      },
      "outputs": [],
      "source": [
        "classes = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
        "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
        "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
        "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
        "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
        "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
        "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
        "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
        "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
        "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
        "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1kwe5EwjBiq"
      },
      "outputs": [],
      "source": [
        "#Rescale is a value by which we will multiply the data before any other processing.\n",
        "#Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our model to process\n",
        "#so we target values between 0 and 1 instead by scaling with a 1/255. factor \n",
        "\n",
        "train_gen = ImageDataGenerator(rescale = 1./255 , validation_split = 0.1)\n",
        "\n",
        "valid_gen = ImageDataGenerator(rescale = 1./255, validation_split = 0.1)\n",
        "\n",
        "test_gen  = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EtwBzUaZtpe",
        "outputId": "80ed5583-c67d-4d6b-e0fb-b88dc1d054ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.preprocessing.image.ImageDataGenerator"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3NFeAo4jHg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "e6ed2b3b-f1be-4441-87db-cdf273e9d3f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ae41d2b89997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'sparse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                           \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                           batch_size= b_s)\n\u001b[0m\u001b[1;32m      8\u001b[0m valid_set = valid_gen.flow_from_directory(directory='/content/Data/train',\n\u001b[1;32m      9\u001b[0m                                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Data/train'"
          ]
        }
      ],
      "source": [
        "b_s = 64\n",
        "target = (224,224)\n",
        "train_set = train_gen.flow_from_directory(directory= '/content/Data/train', \n",
        "                                         target_size= target,\n",
        "                                          class_mode= 'sparse',\n",
        "                                          subset='training',\n",
        "                                          batch_size= b_s)\n",
        "valid_set = valid_gen.flow_from_directory(directory='/content/Data/train',\n",
        "                                           target_size= target,\n",
        "                                          class_mode= 'sparse',\n",
        "                                          subset='validation',\n",
        "                                          batch_size= b_s)\n",
        "test_set = test_gen.flow_from_directory(directory='/content/Data/test',\n",
        "                                         target_size= target,\n",
        "                                          class_mode= 'sparse',\n",
        "                                          batch_size= b_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT0ToeP0_GVX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkSRl8xp_ben"
      },
      "outputs": [],
      "source": [
        "for i in range(train_set.num_classes):\n",
        "   img,l = train_set.next()\n",
        "   print(\"Photo of class\", i+1)\n",
        "   plt.imshow(img[0])\n",
        "   plt.show()\n",
        "train_set.reset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrtM6d6bNrJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b15cc4-bf02-44fb-cff2-5363bdb3607d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 17 15:51:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MVQ5wX5DKMa"
      },
      "source": [
        "##SIMPLE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRaHwuHAQKqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa359b0-9b14-42f9-c24c-89293fbf399a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4096)              411045888 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 104)               426088    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 411,758,984\n",
            "Trainable params: 411,500,616\n",
            "Non-trainable params: 258,368\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "#number of filters 32 , 3x3 kernel size , \n",
        "model.add(Conv2D(32, (3, 3), activation='relu',  padding='same', input_shape=train_set.image_shape)) \n",
        "# total of 32 filters, kernal size(3,3)\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', trainable = False))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', trainable = False))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', trainable = False))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# example output part of the model\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))# fully connected layer\n",
        "model.add(Dense(104, actax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhEUOJQkjaWX"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/DL_Data/tmp'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "   monitor='val_loss',\n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMjIrKq7QiP_"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calling the stopped training model\n",
        "model.load_weights('/content/drive/MyDrive/DL_Data/tmp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er1t2DLbpOow",
        "outputId": "38fc836e-b75b-42ed-9b06-c0b37c8ed5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb8e2c31d50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EvYjQ5OSP2d"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_set,\n",
        "    verbose = 1,\n",
        "    epochs = 20,\n",
        "    validation_data= valid_set,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "model.save(name=\"model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUpvnbqmIv48"
      },
      "outputs": [],
      "source": [
        "y_probs = model.predict(test_set)\n",
        "y_preds = y_probs.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH8ouuTNQILp"
      },
      "outputs": [],
      "source": [
        "y_preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSy-ncNlmQ_0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8aD7lJcINVO"
      },
      "outputs": [],
      "source": [
        "f1 = f1_score(test_set.labels, y_preds, average='macro')\n",
        "cm = confusion_matrix(test_set.labels, y_preds)\n",
        "print(f1, \"\\n\", cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtZXuppKlOO6"
      },
      "outputs": [],
      "source": [
        "cm=confusion_matrix(y_preds,test_set.labels)\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(104,104))\n",
        "disp.plot(ax=ax, xticks_rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDAK_V4KG_Ga"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "#Plot the training Accuracy vs Validation Accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation Accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l8t3UftoWkN"
      },
      "outputs": [],
      "source": [
        "_, acc = model.evaluate(test_set, steps=len(test_set), verbose=0)\n",
        "print('%.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF3dv6GfC35_"
      },
      "source": [
        "##ALEXNET MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP8NXsnsC7CC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79da10c-7b57-4b93-bfea-e15e28af5534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 56, 56, 96)        34944     \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 56, 56, 96)        0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 56, 56, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 256)         614656    \n",
            "                                                                 \n",
            " lambda_1 (Lambda)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 1, 1, 384)         885120    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1, 1, 384)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 1, 1, 384)         1327488   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1, 1, 384)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 1, 1, 256)         884992    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              1052672   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 104)               426088    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,007,272\n",
            "Trainable params: 22,007,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1 = Sequential()\n",
        "#model1.add(layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=train_set.image_shape))\n",
        "model1.add(layers.Conv2D(96, 11, strides=4, padding='same', input_shape=train_set.image_shape))\n",
        "model1.add(layers.Lambda(tf.nn.local_response_normalization))\n",
        "model1.add(layers.Activation('relu'))\n",
        "model1.add(layers.MaxPooling2D(3, strides=2))\n",
        "model1.add(layers.Conv2D(256, 5, strides=4, padding='same'))\n",
        "model1.add(layers.Lambda(tf.nn.local_response_normalization))\n",
        "model1.add(layers.Activation('relu'))\n",
        "model1.add(layers.MaxPooling2D(3, strides=2))\n",
        "model1.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
        "model1.add(layers.Activation('relu'))\n",
        "model1.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
        "model1.add(layers.Activation('relu'))\n",
        "model1.add(layers.Conv2D(256, 3, strides=4, padding='same'))\n",
        "model1.add(layers.Activation('relu'))\n",
        "model1.add(layers.Flatten())\n",
        "model1.add(layers.Dense(4096, activation='relu'))\n",
        "model1.add(layers.Dropout(0.5)) # --> prevents overfitting\n",
        "model1.add(layers.Dense(4096, activation='relu'))\n",
        "model1.add(layers.Dropout(0.5))\n",
        "model1.add(layers.Dense(104, activation='softmax'))\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOCtJ7BcGRRK"
      },
      "outputs": [],
      "source": [
        "model1.compile(\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/DL_Data/alexnet'\n",
        "model_checkpoint_callback1 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "   monitor='val_loss',\n",
        "    verbose=1, \n",
        "    save_best_only=True,\n",
        "    mode='min')\n",
        "    \n"
      ],
      "metadata": {
        "id": "Qcw-8OgXnm5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOSkiX-EGv_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c14788-3767-49fa-cb06-afce1c260253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.4286 - accuracy: 0.0564\n",
            "Epoch 1: val_loss improved from inf to 4.12979, saving model to /content/drive/MyDrive/DL_Data/alexnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 53s 243ms/step - loss: 4.4286 - accuracy: 0.0564 - val_loss: 4.1298 - val_accuracy: 0.0602\n",
            "Epoch 2/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1948 - accuracy: 0.0604\n",
            "Epoch 2: val_loss did not improve from 4.12979\n",
            "181/181 [==============================] - 41s 225ms/step - loss: 4.1948 - accuracy: 0.0604 - val_loss: 4.1396 - val_accuracy: 0.0635\n",
            "Epoch 3/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1928 - accuracy: 0.0610\n",
            "Epoch 3: val_loss improved from 4.12979 to 4.12243, saving model to /content/drive/MyDrive/DL_Data/alexnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 48s 263ms/step - loss: 4.1928 - accuracy: 0.0610 - val_loss: 4.1224 - val_accuracy: 0.0635\n",
            "Epoch 4/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1870 - accuracy: 0.0598\n",
            "Epoch 4: val_loss did not improve from 4.12243\n",
            "181/181 [==============================] - 40s 223ms/step - loss: 4.1870 - accuracy: 0.0598 - val_loss: 4.1349 - val_accuracy: 0.0602\n",
            "Epoch 5/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1893 - accuracy: 0.0579\n",
            "Epoch 5: val_loss did not improve from 4.12243\n",
            "181/181 [==============================] - 41s 226ms/step - loss: 4.1893 - accuracy: 0.0579 - val_loss: 4.1258 - val_accuracy: 0.0602\n",
            "Epoch 6/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1848 - accuracy: 0.0559\n",
            "Epoch 6: val_loss improved from 4.12243 to 4.12050, saving model to /content/drive/MyDrive/DL_Data/alexnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 44s 244ms/step - loss: 4.1848 - accuracy: 0.0559 - val_loss: 4.1205 - val_accuracy: 0.0635\n"
          ]
        }
      ],
      "source": [
        "history1 = model1.fit(\n",
        "    train_set,\n",
        "    epochs = 20,\n",
        "    validation_data = valid_set,\n",
        "    \n",
        "   callbacks=[model_checkpoint_callback1]\n",
        ")\n",
        "model1.save(name=\"model1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(test_set.labels, y_preds, average='macro')\n",
        "cm = confusion_matrix(test_set.labels, y_preds)\n",
        "print(f1, \"\\n\", cm)"
      ],
      "metadata": {
        "id": "mZg0605OZeY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_preds,test_set.labels)\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(104,104))\n",
        "disp.plot(ax=ax, xticks_rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LM0J2GSiZjcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYMKqDEUHgyi"
      },
      "outputs": [],
      "source": [
        "acc1 = history1.history['accuracy']\n",
        "val_acc1 = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "#Plot the training Accuracy vs Validation Accuracy\n",
        "plt.plot(epochs, acc1, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc1, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation Accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jj-pqHtaMiG"
      },
      "source": [
        "##VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18z6m8qWaRKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbe9c2d-10a4-4d97-e806-6a8712f16ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 104)               426088    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,686,632\n",
            "Trainable params: 134,686,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(input_shape=train_set.image_shape,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=4096,activation=\"relu\"))\n",
        "model2.add(Dense(units=4096,activation=\"relu\"))\n",
        "model2.add(Dense(units=104, activation=\"softmax\"))\n",
        "model2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhyXuw8mbPeN"
      },
      "outputs": [],
      "source": [
        "model2.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/DL_Data/vgg'\n",
        "model_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "   monitor='val_loss',\n",
        "    verbose=1, \n",
        "    save_best_only=True,\n",
        "    mode='min')"
      ],
      "metadata": {
        "id": "B8_BAiGMn5rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz__my1Ict_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7489a8ee-cbbe-451e-c62c-d120dd00c516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 32752076.0000 - accuracy: 0.0189\n",
            "Epoch 1: val_loss improved from inf to 4.48875, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 182s 897ms/step - loss: 32752076.0000 - accuracy: 0.0189 - val_loss: 4.4887 - val_accuracy: 0.0163\n",
            "Epoch 2/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.3672 - accuracy: 0.0495\n",
            "Epoch 2: val_loss improved from 4.48875 to 4.24242, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 161s 887ms/step - loss: 4.3672 - accuracy: 0.0495 - val_loss: 4.2424 - val_accuracy: 0.0570\n",
            "Epoch 3/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.2259 - accuracy: 0.0549\n",
            "Epoch 3: val_loss improved from 4.24242 to 4.15515, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 162s 896ms/step - loss: 4.2259 - accuracy: 0.0549 - val_loss: 4.1551 - val_accuracy: 0.0570\n",
            "Epoch 4/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1812 - accuracy: 0.0555\n",
            "Epoch 4: val_loss improved from 4.15515 to 4.12910, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 164s 906ms/step - loss: 4.1812 - accuracy: 0.0555 - val_loss: 4.1291 - val_accuracy: 0.0635\n",
            "Epoch 5/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1693 - accuracy: 0.0611\n",
            "Epoch 5: val_loss improved from 4.12910 to 4.12110, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 163s 899ms/step - loss: 4.1693 - accuracy: 0.0611 - val_loss: 4.1211 - val_accuracy: 0.0635\n",
            "Epoch 6/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1665 - accuracy: 0.0611\n",
            "Epoch 6: val_loss improved from 4.12110 to 4.11865, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 162s 896ms/step - loss: 4.1665 - accuracy: 0.0611 - val_loss: 4.1186 - val_accuracy: 0.0635\n",
            "Epoch 7/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1658 - accuracy: 0.0579\n",
            "Epoch 7: val_loss improved from 4.11865 to 4.11748, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 163s 899ms/step - loss: 4.1658 - accuracy: 0.0579 - val_loss: 4.1175 - val_accuracy: 0.0635\n",
            "Epoch 8/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1656 - accuracy: 0.0611\n",
            "Epoch 8: val_loss improved from 4.11748 to 4.11696, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 161s 889ms/step - loss: 4.1656 - accuracy: 0.0611 - val_loss: 4.1170 - val_accuracy: 0.0635\n",
            "Epoch 9/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1657 - accuracy: 0.0611\n",
            "Epoch 9: val_loss did not improve from 4.11696\n",
            "181/181 [==============================] - 155s 857ms/step - loss: 4.1657 - accuracy: 0.0611 - val_loss: 4.1170 - val_accuracy: 0.0635\n",
            "Epoch 10/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1658 - accuracy: 0.0600\n",
            "Epoch 10: val_loss did not improve from 4.11696\n",
            "181/181 [==============================] - 152s 840ms/step - loss: 4.1658 - accuracy: 0.0600 - val_loss: 4.1171 - val_accuracy: 0.0635\n",
            "Epoch 11/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1659 - accuracy: 0.0611\n",
            "Epoch 11: val_loss improved from 4.11696 to 4.11675, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 162s 896ms/step - loss: 4.1659 - accuracy: 0.0611 - val_loss: 4.1168 - val_accuracy: 0.0635\n",
            "Epoch 12/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1659 - accuracy: 0.0593\n",
            "Epoch 12: val_loss did not improve from 4.11675\n",
            "181/181 [==============================] - 153s 844ms/step - loss: 4.1659 - accuracy: 0.0593 - val_loss: 4.1169 - val_accuracy: 0.0635\n",
            "Epoch 13/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1658 - accuracy: 0.0611\n",
            "Epoch 13: val_loss did not improve from 4.11675\n",
            "181/181 [==============================] - 152s 842ms/step - loss: 4.1658 - accuracy: 0.0611 - val_loss: 4.1171 - val_accuracy: 0.0635\n",
            "Epoch 14/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1661 - accuracy: 0.0607\n",
            "Epoch 14: val_loss did not improve from 4.11675\n",
            "181/181 [==============================] - 152s 842ms/step - loss: 4.1661 - accuracy: 0.0607 - val_loss: 4.1171 - val_accuracy: 0.0635\n",
            "Epoch 15/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1661 - accuracy: 0.0603\n",
            "Epoch 15: val_loss did not improve from 4.11675\n",
            "181/181 [==============================] - 152s 842ms/step - loss: 4.1661 - accuracy: 0.0603 - val_loss: 4.1168 - val_accuracy: 0.0635\n",
            "Epoch 16/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1663 - accuracy: 0.0603\n",
            "Epoch 16: val_loss improved from 4.11675 to 4.11668, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 162s 892ms/step - loss: 4.1663 - accuracy: 0.0603 - val_loss: 4.1167 - val_accuracy: 0.0635\n",
            "Epoch 17/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1664 - accuracy: 0.0611\n",
            "Epoch 17: val_loss improved from 4.11668 to 4.11661, saving model to /content/drive/MyDrive/DL_Data/vgg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r181/181 [==============================] - 163s 897ms/step - loss: 4.1664 - accuracy: 0.0611 - val_loss: 4.1166 - val_accuracy: 0.0635\n",
            "Epoch 18/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1660 - accuracy: 0.0599\n",
            "Epoch 18: val_loss did not improve from 4.11661\n",
            "181/181 [==============================] - 152s 836ms/step - loss: 4.1660 - accuracy: 0.0599 - val_loss: 4.1168 - val_accuracy: 0.0635\n",
            "Epoch 19/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1662 - accuracy: 0.0597\n",
            "Epoch 19: val_loss did not improve from 4.11661\n",
            "181/181 [==============================] - 153s 843ms/step - loss: 4.1662 - accuracy: 0.0597 - val_loss: 4.1170 - val_accuracy: 0.0635\n",
            "Epoch 20/20\n",
            "181/181 [==============================] - ETA: 0s - loss: 4.1661 - accuracy: 0.0600\n",
            "Epoch 20: val_loss did not improve from 4.11661\n",
            "181/181 [==============================] - 153s 842ms/step - loss: 4.1661 - accuracy: 0.0600 - val_loss: 4.1171 - val_accuracy: 0.0635\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0d9d02fa282e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: save() got an unexpected keyword argument 'name'"
          ]
        }
      ],
      "source": [
        "history2 = model2.fit(\n",
        "    train_set,\n",
        "    verbose = 1,\n",
        "    epochs = 20,\n",
        "    validation_data = valid_set,\n",
        "    callbacks=[model_checkpoint_callback2]\n",
        ")\n",
        "model2.save(\"model2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save(\"model2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpLfpB06ns2y",
        "outputId": "9e7390a4-ee3a-47a9-cadd-09d883aec81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJuyWbLRdzYt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c3affcb6-4f39-4e39-eb74-d487a1b17e5f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "acc2 = history2.history['accuracy']\n",
        "val_acc2 = history2.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc2) + 1)\n",
        "\n",
        "#Plot the training Accuracy vs Validation Accuracy\n",
        "plt.plot(epochs, acc2, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc2, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation Accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs2 = model2.predict(test_set)\n",
        "y_preds2 = y_probs2.argmax(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJFxcmaBg0r4",
        "outputId": "eb0ec073-c5df-4dcd-96cc-3c694cd31c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 60s 297ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42QA8AQ7GNhY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZofUKI_GbU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb51015b-8909-4691-cef4-d53e6c9b5900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0011110795373817169 \n",
            " [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "f1 = f1_score(test_set.labels, y_preds2, average='macro')\n",
        "cm = confusion_matrix(test_set.labels, y_preds2)\n",
        "print(f1, \"\\n\", cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bRN4QO2Gc1h"
      },
      "outputs": [],
      "source": [
        "cm=confusion_matrix(y_preds2,test_set.labels)\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(104,104))\n",
        "disp.plot(ax=ax, xticks_rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model2.evaluate(test_set, steps=len(test_set), verbose=0)\n",
        "print('%.3f' % (acc * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF5wFu5Zgg4k",
        "outputId": "9bc38ea9-61ed-4021-bf81-ce39afc6c50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omp_aCFmZpMs"
      },
      "source": [
        "## GoogleNet/Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7tUoykcSr0i"
      },
      "outputs": [],
      "source": [
        "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
        "  # Input: \n",
        "  # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
        "  # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
        "  # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
        "  # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
        "\n",
        "  # 1st path:\n",
        "  path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
        "\n",
        "  # 2nd path\n",
        "  path2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
        "  path2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', activation = 'relu', trainable = False)(path2)\n",
        "\n",
        "  # 3rd path\n",
        "  path3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
        "  path3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', activation = 'relu', trainable = False)(path3)\n",
        "\n",
        "  # 4th path\n",
        "  path4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
        "  path4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', activation = 'relu')(path4)\n",
        "\n",
        "  output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
        "\n",
        "  return output_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56TCFSQ1Sz_j"
      },
      "outputs": [],
      "source": [
        "def GoogLeNet():\n",
        "  # input layer \n",
        "  input_layer = Input(shape = train_set.image_shape)\n",
        "\n",
        "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
        "\n",
        "  # convolutional layer: filters = 64, strides = 1\n",
        "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu')(X)\n",
        "\n",
        "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
        "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', activation = 'relu')(X)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
        "\n",
        "  # 1st Inception block\n",
        "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n",
        "\n",
        "  # 2nd Inception block\n",
        "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, f3_conv5 = 96, f4 = 64)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
        "\n",
        "  # 3rd Inception block\n",
        "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, f3_conv5 = 48, f4 = 64)\n",
        "\n",
        "  # Extra network 1:\n",
        "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
        "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X1)\n",
        "  X1 = Flatten()(X1)\n",
        "  X1 = Dense(1024, activation = 'relu')(X1)\n",
        "  X1 = Dropout(0.7)(X1)\n",
        "  X1 = Dense(104, activation = 'softmax')(X1)\n",
        "\n",
        "  \n",
        "  # 4th Inception block\n",
        "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # 5th Inception block\n",
        "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # 6th Inception block\n",
        "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # Extra network 2:\n",
        "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
        "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n",
        "  X2 = Flatten()(X2)\n",
        "  X2 = Dense(1024, activation = 'relu')(X2)\n",
        "  X2 = Dropout(0.7)(X2)\n",
        "  X2 = Dense(104, activation = 'softmax')(X2)\n",
        "  \n",
        "  \n",
        "  # 7th Inception block\n",
        "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
        "                      f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
        "\n",
        "  # 8th Inception block\n",
        "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # 9th Inception block\n",
        "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # Global Average pooling layer \n",
        "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
        "\n",
        "  # Dropoutlayer \n",
        "  X = Dropout(0.4)(X)\n",
        "\n",
        "  # output layer \n",
        "  X = Dense(104, activation = 'softmax')(X)\n",
        "  \n",
        "  # model\n",
        "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFk19BqLzLdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17478691-f7ec-4bd6-8bf3-35c106c62bfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7060085790>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#model3 = Sequential()\n",
        "model3 = GoogLeNet()\n",
        "model3.load_weights(\"/content/drive/MyDrive/DL_Data/google\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLpXp1nkzPyI"
      },
      "outputs": [],
      "source": [
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ouymrj7gCppT"
      },
      "outputs": [],
      "source": [
        "model3.compile(\n",
        "     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-zrUrwFCvfc"
      },
      "outputs": [],
      "source": [
        "history3 = model3.fit(\n",
        "    train_set,\n",
        "    verbose = 1,\n",
        "    epochs = 20,\n",
        "    validation_data = valid_set\n",
        ")\n",
        "model3.save(\"model3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgG5SLoFu-Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1828b5a1-734a-4de2-c311-76c06db5e4f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 46/200 [=====>........................] - ETA: 27s"
          ]
        }
      ],
      "source": [
        "y_probs3 = model3.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiiEiQ_avIbr"
      },
      "outputs": [],
      "source": [
        "y_probs3=np.array(y_probs3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ealGTgxyPqr"
      },
      "outputs": [],
      "source": [
        "y_preds3 = y_probs3.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEs_fRrkzp36"
      },
      "outputs": [],
      "source": [
        "y_probs3 = y_probs3.reshape(3*3712,104)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ3VpcYv0OOS"
      },
      "outputs": [],
      "source": [
        "y_probs3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zin-4zkVwGJL"
      },
      "outputs": [],
      "source": [
        "f1 = f1_score(test_set.labels, y_probs3, average='macro')\n",
        "cm = confusion_matrix(test_set.labels, y_probs3)\n",
        "print(f1, \"\\n\", cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUBdeDSQwLuL"
      },
      "outputs": [],
      "source": [
        "cm3=confusion_matrix(y_preds3,test_set.labels)\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix=cm3,display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(104,104))\n",
        "disp.plot(ax=ax, xticks_rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yReOkpBtwZiy"
      },
      "outputs": [],
      "source": [
        "acc3 = history3.history['accuracy']\n",
        "val_acc3 = history3.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "#Plot the training Accuracy vs Validation Accuracy\n",
        "plt.plot(epochs, acc3, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc3, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation Accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7B4MfeiGHSd"
      },
      "source": [
        "##ENSEMBLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8911fPL99k7"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape = train_set.image_shape)\n",
        "\n",
        "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
        "\n",
        "  # convolutional layer: filters = 64, strides = 1\n",
        "X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu', trainable = False)(X)\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
        "\n",
        "  # 1st Inception block\n",
        "\n",
        "X = Conv2D(filters=32, kernel_size=(3,3), padding='same', strides=(2,2), trainable = False)(X)\n",
        "X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n",
        "X = Inception_block(X, f1 = 32, f2_conv1 = 48, f2_conv3 = 64, f3_conv1 = 4, f3_conv5 = 16, f4 = 16)\n",
        "X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
        "X = (Dense(4096, activation = 'relu', trainable = False)) (X)\n",
        "X = (Dense(104, activation = 'softmax')) (X)\n",
        "X = Dropout(0.5)(X)\n",
        "model4 = Model(input_layer, [X])\n",
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz2wR_UABd6V"
      },
      "outputs": [],
      "source": [
        "model4.compile(\n",
        "     optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jsd3qdiCUfk"
      },
      "outputs": [],
      "source": [
        "history4 = model4.fit(\n",
        "    train_set,\n",
        "    verbose = 1,\n",
        "    epochs = 20,\n",
        "    validation_data = valid_set\n",
        ")\n",
        "model4.save(name=\"model4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec8ANcao5Vkx"
      },
      "outputs": [],
      "source": [
        "y_probs4 = model4.predict(test_set)\n",
        "y_preds4 = y_probs4.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAJ3esLA5W4B"
      },
      "outputs": [],
      "source": [
        "f1 = f1_score(test_set.labels, y_preds4, average='macro')\n",
        "cm4 = confusion_matrix(test_set.labels, y_preds4)\n",
        "print(f1, \"\\n\", cm4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc3d9BEh5XDh"
      },
      "outputs": [],
      "source": [
        "cm4=confusion_matrix(y_preds4,test_set.labels)\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix=cm4,display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(104,104))\n",
        "disp.plot(ax=ax, xticks_rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqjWBakt5lWy"
      },
      "outputs": [],
      "source": [
        "acc = history4.history['accuracy']\n",
        "val_acc = history4.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "#Plot the training Accuracy vs Validation Accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation Accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Iz-qAcZqpy"
      },
      "source": [
        "##Pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6juClNZZwSi"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceqst3ZkeYcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529241b1-2c7a-4920-b4b2-18953e89a861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1000)              138357544 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 104)               104104    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,461,648\n",
            "Trainable params: 138,461,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "modelP = keras.models.Sequential()\n",
        "modelP.add(VGG16 (weights='imagenet',pooling='avg'))\n",
        "\n",
        "modelP.add(Dense(units=104, activation=\"softmax\"))\n",
        "modelP.summary ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yoBZw_dEPZV"
      },
      "outputs": [],
      "source": [
        "modelP.compile(\n",
        "     optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), \n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIQ4nFYREQEE"
      },
      "outputs": [],
      "source": [
        "historyP = modelP.fit(\n",
        "    train_set,\n",
        "    verbose = 1,\n",
        "    epochs = 20,\n",
        "    validation_data = valid_set\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5jSZu8kHCD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b62aa28-32ee-45c3-e52d-5fa37f6ee91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "modelP.save(\"modelP\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accP = historyP.history['accuracy']\n",
        "val_accP = historyP.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(accP) + 1)\n",
        "\n",
        "#Plot the training Accuracy vs Validation Accuracy\n",
        "plt.plot(epochs, accP, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_accP, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation Accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "V_gol89E-qKJ",
        "outputId": "e309e705-335e-462c-c1e8-b96fc008b83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probsP = modelP.predict(test_set)\n",
        "y_predsP = y_probsP.argmax(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZCu-TI--wcx",
        "outputId": "216de00b-bc7f-48f3-86f3-517a63a2581b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 67s 337ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(test_set.labels, y_predsP, average='macro')\n",
        "cm = confusion_matrix(test_set.labels, y_predsP)\n",
        "print(f1, \"\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg1ti0Ut-0rh",
        "outputId": "c7f6a047-313e-4ba7-c03d-f69a1d7a0d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0011110795373817169 \n",
            " [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_predsP,test_set.labels)\n",
        "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(104,104))\n",
        "disp.plot(ax=ax, xticks_rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yRi5Fjp9--T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = modelP.evaluate(test_set, steps=len(test_set), verbose=0)\n",
        "print('%.3f' % (acc * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7YLEUEi_s_i",
        "outputId": "6430a6b4-3943-4d9a-f952-690235bac52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.132\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sF3dv6GfC35_",
        "omp_aCFmZpMs",
        "M7B4MfeiGHSd"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}